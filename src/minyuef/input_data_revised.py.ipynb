{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "from six.moves import urllib\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_BALL_SAMPS = 71709\n",
    "OUTERMOST_SPHERE_SHAPE = [49, 97]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_queues(train_dir, fake_data=False, shuffle=True, num_epochs=None,\n",
    "                    num_expected_examples=None):\n",
    "\n",
    "    print('get_data_queues: num_epochs =', num_epochs, type(num_epochs))\n",
    "\n",
    "    yamlRE = re.compile(r'.+_.+_[0123456789]+\\.yaml')\n",
    "    recList = []\n",
    "    if not fake_data:\n",
    "        for fn in os.listdir(train_dir):\n",
    "            if yamlRE.match(fn):\n",
    "                words = fn[:-5].split('_')\n",
    "                base = words[0]\n",
    "                idx = int(words[2])\n",
    "                featureFName = os.path.join(train_dir,\n",
    "                                            '%s_rotBallSamp_%d.doubles' % (base, idx))\n",
    "                labelFName = os.path.join(train_dir,\n",
    "                                          '%s_rotEdgeSamp_%d.doubles' % (base, idx))\n",
    "\n",
    "                recList.append('%s,%s' % (featureFName, labelFName))\n",
    "\n",
    "    assert len(recList) == num_expected_examples, ('Found %s examples, expected %d'\n",
    "                                                   % (len(recList),\n",
    "                                                      num_expected_examples))\n",
    "\n",
    "    print('get_data_queues: len(recList) =', len(recList))\n",
    "    print('get_data_queues: recList[:10] =', recList[:10])\n",
    "\n",
    "\n",
    "    featureNameT, labelNameT = tf.decode_csv(recList, [[\"\"], [\"\"]],\n",
    "                                                name='decodeCSV')\n",
    "    print(\"feature\",featureNameT, \"label\",labelNameT)\n",
    "   #namePairQ = tf.train.slice_input_producer([featureNameT, labelNameT],\n",
    "               #                               shuffle=shuffle,\n",
    "                       #                       num_epochs=num_epochs)\n",
    "    feature_label_pair_list = tf.stack([featureNameT, labelNameT], axis=-1)\n",
    "    print(\"=== dataset aligned === \",feature_label_pair_list)\n",
    "    \n",
    "    \n",
    "   # dataset = tf.data.Dataset.from_tensor_slices((featureNameT,labelNameT))\n",
    "    #dataset = feature_label_pair_list\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(feature_label_pair_list)\n",
    "    print(\"=== dataset before shuffling is === \",dataset)\n",
    "   # print(list(dataset.take(1)))\n",
    "   # print(list(dataset.take(2)))\n",
    "\n",
    "    namePairQ = dataset.shuffle(num_expected_examples).repeat(num_epochs)\n",
    "    print(\"name pair q \",namePairQ)\n",
    "    return namePairQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pair_of_files(namePairQ):\n",
    "    print('read_pair_of_files: namePairQ[0] =', namePairQ[0])\n",
    "    print('read_pair_of_files: namePairQ[1] =', namePairQ[1])\n",
    "\n",
    "    fString = tf.read_file(namePair.numpy()[0], name='featureReadFile')\n",
    "    fVals = tf.to_float(tf.reshape(tf.decode_raw(fString,\n",
    "                                     dtypes.float64,\n",
    "                                     name='featureDecode'),\n",
    "                                   [N_BALL_SAMPS]),\n",
    "                        name='featureToFloat')\n",
    "    lString = tf.read_file(namePair.numpy()[1], name='labelReadFile')\n",
    "    lVals = tf.to_float(tf.decode_raw(lString, dtypes.float64,\n",
    "                                      name='labelDecode'),\n",
    "                        name='labelToFloat')\n",
    "    nRows, nCols = OUTERMOST_SPHERE_SHAPE\n",
    "    nOuterSphere = nRows * nCols\n",
    "    lVals = tf.cond(tf.less(tf.reduce_max(lVals), 1.0e-12),\n",
    "                    lambda: tf.constant(1.0/float(nOuterSphere),\n",
    "                                        dtype=dtypes.float32,\n",
    "                                        shape=[nOuterSphere]),\n",
    "                    lambda: tf.nn.l2_normalize(lVals, 0))\n",
    "    lVals = tf.reshape(lVals, OUTERMOST_SPHERE_SHAPE)\n",
    "\n",
    "    print('read_pair_of_files: fVals, lVals =', fVals, lVals)\n",
    "\n",
    "    return fVals, lVals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_data_queues: num_epochs = 1 <class 'int'>\n",
      "get_data_queues: len(recList) = 2\n",
      "get_data_queues: recList[:10] = ['test/block_rotBallSamp_4137447.doubles,test/block_rotEdgeSamp_4137447.doubles', 'test/block_rotBallSamp_3913814.doubles,test/block_rotEdgeSamp_3913814.doubles']\n",
      "feature tf.Tensor(\n",
      "[b'test/block_rotBallSamp_4137447.doubles'\n",
      " b'test/block_rotBallSamp_3913814.doubles'], shape=(2,), dtype=string) label tf.Tensor(\n",
      "[b'test/block_rotEdgeSamp_4137447.doubles'\n",
      " b'test/block_rotEdgeSamp_3913814.doubles'], shape=(2,), dtype=string)\n",
      "=== dataset aligned ===  tf.Tensor(\n",
      "[[b'test/block_rotBallSamp_4137447.doubles'\n",
      "  b'test/block_rotEdgeSamp_4137447.doubles']\n",
      " [b'test/block_rotBallSamp_3913814.doubles'\n",
      "  b'test/block_rotEdgeSamp_3913814.doubles']], shape=(2, 2), dtype=string)\n",
      "=== dataset before shuffling is ===  <DatasetV1Adapter shapes: (2,), types: tf.string>\n",
      "name pair q  <DatasetV1Adapter shapes: (2,), types: tf.string>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'DatasetV1Adapter' object does not support indexing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-8bbe32f6c06e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m namePairQ= get_data_queues(train_dir, shuffle=True, num_epochs=num_epochs,\n\u001b[1;32m      6\u001b[0m                                num_expected_examples=num_expected_examples)\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mflPairList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mread_pair_of_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamePairQ\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_threads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-141-8bbe32f6c06e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m namePairQ= get_data_queues(train_dir, shuffle=True, num_epochs=num_epochs,\n\u001b[1;32m      6\u001b[0m                                num_expected_examples=num_expected_examples)\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mflPairList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mread_pair_of_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamePairQ\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_threads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-140-c0a4f8ce2ddf>\u001b[0m in \u001b[0;36mread_pair_of_files\u001b[0;34m(namePairQ)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_pair_of_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamePairQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'read_pair_of_files: namePairQ[0] ='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamePairQ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'read_pair_of_files: namePairQ[1] ='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamePairQ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfString\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamePair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'featureReadFile'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DatasetV1Adapter' object does not support indexing"
     ]
    }
   ],
   "source": [
    "train_dir = 'test'\n",
    "num_epochs = 1\n",
    "num_expected_examples = 2\n",
    "read_threads = 1\n",
    "namePairQ= get_data_queues(train_dir, shuffle=True, num_epochs=num_epochs,\n",
    "                               num_expected_examples=num_expected_examples)\n",
    "flPairList = [read_pair_of_files(namePairQ) for _ in range(read_threads)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: id=830, shape=(2,), dtype=string, numpy=\n",
      "array([b'test/block_rotBallSamp_3913814.doubles',\n",
      "       b'test/block_rotEdgeSamp_3913814.doubles'], dtype=object)>]\n",
      "b'test/block_rotEdgeSamp_3913814.doubles'\n"
     ]
    }
   ],
   "source": [
    "namePairQ\n",
    "namePairQ\n",
    "print(list(namePairQ.take(1)))\n",
    "\n",
    "#for label in label_ds.take(10):\n",
    " # print(label_names[label.numpy()])\n",
    "\n",
    "for namePair in namePairQ.take(10):\n",
    "    print(namePair.numpy()[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-149-1938e162dda0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamePairQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/tensorflow/python/ops/functional_ops.py\u001b[0m in \u001b[0;36mmap_fn\u001b[0;34m(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name)\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0mback_prop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mback_prop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m         maximum_iterations=n)\n\u001b[0m\u001b[1;32m    498\u001b[0m     \u001b[0mresults_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr_a\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   3530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3531\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3532\u001b[0;31m         \u001b[0mloop_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3534\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, lv)\u001b[0m\n\u001b[1;32m   3523\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[1;32m   3524\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[0;32m-> 3525\u001b[0;31m         \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3527\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/tensorflow/python/ops/functional_ops.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(i, tas)\u001b[0m\n\u001b[1;32m    484\u001b[0m       \"\"\"\n\u001b[1;32m    485\u001b[0m       \u001b[0mpacked_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem_ta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem_ta\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melems_ta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m       \u001b[0mpacked_fn_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m       \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_same_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0melems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpacked_fn_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m       \u001b[0mflat_fn_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_fn_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-149-1938e162dda0>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamePairQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "def load_and_preprocess_image(path):\n",
    "  image = tf.read_file(path)\n",
    "  return preprocess_image(image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
