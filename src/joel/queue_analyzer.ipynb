{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import datetime as dtm\n",
    "from subprocess import Popen, PIPE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.gridspec import GridSpec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch squeue data and construct a full table ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Popen(['ssh', 'bridges.psc.edu', 'squeue', '--array', '--format', '%all'], stdout=PIPE) as proc:\n",
    "    recs = proc.stdout.readlines()\n",
    "\n",
    "time_of_read = dtm.datetime.now()\n",
    "\n",
    "cols = recs[0].decode().strip().split('|')\n",
    "print(cols)\n",
    "recs = recs[1:]\n",
    "\n",
    "recL = []\n",
    "for rec in recs:\n",
    "    recL.append({a : b for a, b in zip(cols, rec.decode().strip().split('|'))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_time(tstr):\n",
    "    if '-' in tstr:\n",
    "        days, tstr = tstr.split('-')\n",
    "        days = int(days)\n",
    "    else:\n",
    "        days = 0\n",
    "    words = tstr.split(':')\n",
    "    tot = 0\n",
    "    for word in words:\n",
    "        tot += 60 * tot + int(word)\n",
    "    tot += 24 * 60 * 60 * days\n",
    "    return tot\n",
    "\n",
    "# parse_time('3-00:04:05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integer_fields = ['MIN_CPUS', 'MIN_TMP_DISK', 'JOBID', 'PRIORITY', 'CPUS', 'NODES', 'ARRAY_JOB_ID']\n",
    "time_fields = ['TIME_LIMIT', 'TIME_LEFT', 'TIME']\n",
    "\n",
    "# Convert strings to appropriate field types in place\n",
    "for rec in recL:\n",
    "    for key in integer_fields:\n",
    "        try:\n",
    "            rec[key] = int(rec[key])\n",
    "        except TypeError:\n",
    "            pass\n",
    "    for key in time_fields:\n",
    "        try:\n",
    "            rec[key] = parse_time(rec[key])\n",
    "        except ValueError:\n",
    "            print('time interval conversion failed: %s = %s' % (key, rec[key]))\n",
    "            print(rec)\n",
    "            rec[key] = 0\n",
    "    rec['TIME_SINCE_SUBMIT'] = (time_of_read - dtm.datetime.fromisoformat(rec['SUBMIT_TIME'])).total_seconds()\n",
    "\n",
    "# print(recL[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullDF = pd.DataFrame.from_records(recL)\n",
    "print(fullDF.columns)\n",
    "#fullDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullDF['JOBS'] = 1\n",
    "fullDF['CPU_SEC_USED'] = fullDF['CPUS'] * fullDF['TIME']\n",
    "fullDF['CPU_SEC_REMAIN'] = fullDF['CPUS'] * fullDF['TIME_LEFT']\n",
    "#fullDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch sinfo data and construct a full table ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Popen(['ssh', 'bridges.psc.edu', 'sinfo', '--format', '%all'], stdout=PIPE) as proc:\n",
    "    recs = proc.stdout.readlines()\n",
    "\n",
    "time_of_read_sinfo = dtm.datetime.now()\n",
    "\n",
    "cols = recs[0].decode().strip().split('|')\n",
    "print(cols)\n",
    "recs = recs[1:]\n",
    "\n",
    "recL = []\n",
    "for rec in recs:\n",
    "    recL.append({a : b for a, b in zip(cols, rec.decode().strip().split('|'))})\n",
    "\n",
    "sinfoDF = pd.DataFrame.from_records(recL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_counts(row):\n",
    "    fields = row['CPUS(A/I/O/T) '].split('/')\n",
    "    n_A, n_I, n_O, n_T = [int(fld) for fld in fields]\n",
    "    return pd.Series({'n_A':n_A, 'n_I':n_I, 'n_O':n_O, 'n_T':n_T})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sinfoDF.apply(split_counts, axis=1)\n",
    "sinfoDF = pd.concat([sinfoDF, df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tables of running jobs by partition and user ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runDF = fullDF[fullDF.STATE == 'RUNNING'][['PARTITION', 'USER', 'ACCOUNT', 'CPUS', 'MIN_CPUS', 'NODES',\n",
    "                                           'JOBS', 'CPU_SEC_USED', 'CPU_SEC_REMAIN']]\n",
    "for partition, df in runDF.groupby(['PARTITION', 'USER', 'ACCOUNT']).sum().groupby('PARTITION'):\n",
    "    display(df.sort_values(by=['CPUS', 'JOBS', 'CPU_SEC_REMAIN'], ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tables of queued jobs by partition and user ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waitDF = fullDF[fullDF.STATE != 'RUNNING'][['PARTITION', 'USER', 'ACCOUNT', 'CPUS', 'MIN_CPUS', 'NODES',\n",
    "                                           'JOBS', 'CPU_SEC_USED', 'CPU_SEC_REMAIN', 'TIME_SINCE_SUBMIT']]\n",
    "for partition, df in waitDF.groupby(['PARTITION', 'USER', 'ACCOUNT']).sum().groupby('PARTITION'):\n",
    "    display(df.sort_values(by=['CPUS', 'JOBS', 'CPU_SEC_REMAIN'], ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullDF.STATE.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of average wait time by user ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = waitDF[waitDF.PARTITION == 'RM-shared'].groupby(['USER', 'ACCOUNT']).sum()\n",
    "df['MEAN_TIME_SINCE_SUBMIT'] = df['TIME_SINCE_SUBMIT']/df['JOBS']\n",
    "df.sort_values(['MEAN_TIME_SINCE_SUBMIT'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of CPU allocations by partition ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitionCPUDF = sinfoDF[['PARTITION ', 'n_A', 'n_I', 'n_O', 'n_T']].groupby(['PARTITION ']).sum()\n",
    "partitionCPUDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  queue_plot(axes, runDF, waitDF, partition):\n",
    "    blockL = []\n",
    "    txtL = []\n",
    "    baseX = 0.0\n",
    "    baseY = 0.0\n",
    "    maxLWd = 0.0\n",
    "    maxTotHt = 0.0\n",
    "    df = waitDF[waitDF.PARTITION == partition].groupby(['USER', 'ACCOUNT']).sum()\n",
    "    df['MEAN_TIME_SINCE_SUBMIT'] = df['TIME_SINCE_SUBMIT']/df['JOBS']\n",
    "    df.sort_values(['MEAN_TIME_SINCE_SUBMIT'],ascending=False)\n",
    "    for idx, row in df.reset_index().sort_values(['MEAN_TIME_SINCE_SUBMIT'], ascending=False).iterrows():\n",
    "        ht = row['CPUS']\n",
    "        wd = float(row['CPU_SEC_REMAIN'])/(3600. * row['CPUS'])\n",
    "        rect = Rectangle((baseX, baseY), wd, ht, ec='black')\n",
    "        blockL.append(axes.add_artist(rect))\n",
    "        ltxt = plt.Annotation('%s (%s) %.2f hours' % (row['USER'], row['ACCOUNT'],\n",
    "                                                   row['MEAN_TIME_SINCE_SUBMIT']/3600.0),\n",
    "                              (baseX + 0.5*wd, baseY + 0.5*ht),\n",
    "                              va='center', ha='center'\n",
    "                             )\n",
    "        txtL.append(axes.add_artist(ltxt))\n",
    "        baseY += ht\n",
    "        maxLWd = max(maxLWd, wd)\n",
    "    maxTotHt = max(maxTotHt, baseY)\n",
    "    baseX = 0.0\n",
    "    baseY = 0.0\n",
    "    maxRWd = 0.0\n",
    "    df = runDF[runDF.PARTITION == partition].groupby(['USER', 'ACCOUNT']).sum()\n",
    "    df['MEAN_HOURS_REMAIN'] = df['CPU_SEC_REMAIN']/(3600. * df['CPUS'])\n",
    "    df.sort_values(['MEAN_HOURS_REMAIN'],ascending=False)\n",
    "    for idx, row in df.reset_index().sort_values(['CPUS'], ascending=False).iterrows():\n",
    "        ht = row['CPUS']\n",
    "        wd = float(row['MEAN_HOURS_REMAIN'])\n",
    "        rect = Rectangle((baseX - wd, baseY), wd, ht, ec='black', fc='red')\n",
    "        blockL.append(axes.add_artist(rect))\n",
    "        ltxt = plt.Annotation('%s (%s)' % (row['USER'], row['ACCOUNT']),\n",
    "                              (baseX - 0.5*wd, baseY + 0.5*ht),\n",
    "                              va='center', ha='center'\n",
    "                             )\n",
    "        txtL.append(axes.add_artist(ltxt))\n",
    "        baseY += ht\n",
    "        maxRWd = max(maxRWd, wd)\n",
    "    maxTotHt = max(maxTotHt, baseY)\n",
    "    axes.set_xlim(-maxRWd, maxLWd)\n",
    "    axes.set_ylim(0.0, maxTotHt)\n",
    "    axes.set_xlabel('Hours per CPU')\n",
    "    axes.set_title('%s\\n<- Running | Waiting ->' % partition)\n",
    "    return maxTotHt\n",
    "\n",
    "#fix, axes = plt.subplots(1)\n",
    "#queue_plot(axes, runDF, waitDF, 'GPU-shared')\n",
    "#plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpu_plot(axes, partitionCPUDF, partition):\n",
    "    axes0.set_xlim(0.0, 1.0)\n",
    "    baseY = 0.0\n",
    "    df = partitionCPUDF.reset_index()\n",
    "    for idx, row in df.iterrows():\n",
    "        this_pt = row['PARTITION '].strip()\n",
    "        if this_pt == partition:\n",
    "            ht = row['n_A']\n",
    "            rect = Rectangle((0.0, baseY), 1.0, ht, ec='black', fc='cyan')\n",
    "            axes.add_artist(rect)\n",
    "            ltxt = plt.Annotation('alloc', (0.5, baseY + 0.5*ht), va='center', ha='center')\n",
    "            axes.add_artist(ltxt)\n",
    "            baseY += ht\n",
    "    \n",
    "            ht = row['n_I']\n",
    "            rect = Rectangle((0.0, baseY), 1.0, ht, ec='black', fc='cyan', hatch='/')\n",
    "            axes.add_artist(rect)\n",
    "            ltxt = plt.Annotation('idle', (0.5, baseY + 0.5*ht), va='center', ha='center')\n",
    "            axes.add_artist(ltxt)\n",
    "            baseY += ht\n",
    "    \n",
    "            ht = row['n_O']\n",
    "            rect = Rectangle((0.0, baseY), 1.0, ht, ec='black', fc='cyan', hatch='+')\n",
    "            axes.add_artist(rect)\n",
    "            ltxt = plt.Annotation('other', (0.5, baseY + 0.5*ht), va='center', ha='center')\n",
    "            axes.add_artist(ltxt)\n",
    "            baseY += ht\n",
    "    return baseY\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.print_figure_kwargs = {'bbox_inches':None}\n",
    "%matplotlib inline\n",
    "#%matplotlib qt\n",
    "plt.rcParams[\"figure.figsize\"] = [16, 10]\n",
    "\n",
    "for partition in fullDF.PARTITION.unique():\n",
    "    fig = plt.figure()\n",
    "    gs = GridSpec(1, 2, width_ratios=[1, 10])\n",
    "    gs.update(wspace=0.0)\n",
    "    axes0 = fig.add_subplot(gs[0])\n",
    "    axes1 = fig.add_subplot(gs[1], sharey=axes0)\n",
    "    plt.setp(axes1.get_yticklabels(), visible=False)\n",
    "    axes0.set_ylabel('CPUs')\n",
    "    plt.setp(axes0.get_xticklabels(), visible=False)\n",
    "    axes0.get_xaxis().set_ticks([])\n",
    "    ht1 = queue_plot(axes1, runDF, waitDF, partition)\n",
    "    ht2 = cpu_plot(axes0, partitionCPUDF, partition)\n",
    "    axes1.set_ylim(0.0, max(ht1, ht2))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (py3Env)",
   "language": "python",
   "name": "py3env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
